##All Your Games are Belong to Us Pt 2##

AlphaGo - go (was considered the toughest to win - https://www.explainxkcd.com/wiki/index.php/1002:_Game_AIs)
  - as recently as 1 year ago, computer experts thoguht we were still 10 year away from building a computer that could defeat GO champions
  - best algos could easily be beaten by moderately good players
Why so tough to beat?
  - There are games (like tic-tac-toe) that have a finite number of possible moves.  These games generally have mathematical solutions and are considered 'solved'
  - Chess had too many potential games for it to be a 'solved' game but some pieces were more valuable than others so it could choose the best 2-3 moves and play out possible games for those moves (then select the best overall move)
  - Go had more possible game combos than there are atoms in the known universe AND all pieces had the same value so it couldn't be 'won' in that way
How did we solve it?
  - Combination of 'deep learning' and 'monte carlo tree search'
  - Deep Learning
    - Give computer basic rules of a game and have it play over and over and over while it abstracts out strategies and best practices
    - Seeded with a number of base games (30 million?)
    - Played against a modified version of itself that had been trained to make the most likely human moves
Monte Carlo Tree Search

=========

Artificial Intelligence - it's been kicking our butt at our favorite board games for decades now.  But humanity, crafty devils that we are, has long had an ace up our sleeves.  No, I'm not talking poker - I'm talking Go.

[INTRO]

/ Welcome to CompChomp...the only show on the internets where artificial intelligence and the Tokugawa Shogunate intersect.
/ Welcome to CompChomp...the only show on the internets where a trip to Monte Carlo is a legitimate business expense.

Go is old. 5,500 years old to be exact. And people have been playing it continuously for that entire time. So we've had a chance to become experts. And, given the complexity of the game, we needed all the time we could get.

From the time we started teaching computers to play games, Go was considered the impossible dream.  There are games like tic-tac-toe (naughts and crosses for my British friends) that have a small, finite number of possibilities.  Games like these have mathematical solutions and if you can solve it with math you don't stand a chance against a computer.  Chess was tougher because there were too many possible games for it to have a mathematical solution.  However, some pieces, like their majesties the king and queen, are more valuable than others.  This gave us the ability to choose a few moves that favored those pieces - the computer could then play out the possible games for those moves and select the single best move overall.  It took a while, but with improved computing power, this method eventually made computers unstoppable in chess.

Go is different though.  It's played by placing a stone on a 19 x 19 grid in order to surround more territory than your opponent.  There are more possible game combinations than there are atoms in the known universe AND every piece has exactly the same value so the chess approach won't work.  Brute force alone would never bring victory to the computers.  As recently as last year, experts in AI were predicting that we were about 10 years away from having a computer that could defeat a top human Go player.

And then, AlphaGo happened.

In October of 2015, AlphaGo, a computer program developed by Google DeepMind faced off against second dan, Fan Hui - the European GO champion.  AlphaGo won all 5 games making this the first time that a computer had defeated a professional human player on the full-sized board without any handicaps.

Five months later, the computer was matched up against Lee Sodol a 9th-dan player (that's 9 dans out of 9), a man widely considered to be one of the top human players.  After five games (played out over 25 loooooong hours), AlphaGo emerged victorious winning 4 of the 5 matches.

What changed between the experts making their predictions and the computers showing us up?  Advancements in machine learning!  

Since GO has so many possible moves during each turn (remember the whole more atoms than the universe thing) GO computers can't search through every  move to determine the best one.  Instead, they use an algorithm called Monte Carlo Tree Search.  The computers take a random sample of the possible moves, check out the likely outcomes for each of those moves, then choose the best option from that sample.  AlphaGo is no different than other not-so-skilled GO playing computers on this front.

Where AlphaGo shines
  - neural networks help prune options during MCTS
  - neural networks are improved by playing against each other (seeded with 30 million human games, played countless additional games against each other)

  Is time to fear our robot overlords? Not-so-much. GO is still a fixed domain with a defined goal. Ask AlphaGo to play chess and it will probably do worse than my kid sister.  Maybe not...I haven't got a kid sister.

  CHOMP!
